{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "from cued_sf2_lab.familiarisation import load_mat_img, plot_image\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure id=\"figure-5\">\n",
    "<div style=\"background-color: white\">\n",
    "\n",
    "![](figures/dwt.svg)\n",
    "</div>\n",
    "\n",
    "<figcaption style=\"text-align: center\">\n",
    "\n",
    "Figure 5: An $L$ level binary discrete wavelet transform.</figcaption></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 The Discrete Wavelet Transform (DWT)\n",
    "\n",
    "<div class=\"alert alert-warning alert-block\">\n",
    "    \n",
    "This notebook is incomplete!</div>\n",
    "\n",
    "The final method of energy compaction that we shall investigate, is the\n",
    "discrete wavelet transform. In some ways this attempts to combine the best features of\n",
    "the Laplacian pyramid and the DCT:\n",
    "\n",
    "* Like the pyramid, the DWT analyses the image at a range of different\n",
    "  scales (levels) and employs symmetrical filters;\n",
    "\n",
    "* Like the DCT, the DWT avoids any expansion in the number of coefficients.\n",
    "\n",
    "Wavelet theory was evolved by mathematicians during the 1980's. As with the LBT, we shall not attempt to teach this theory here, just illustrate a relatively simple form of it.\n",
    "\n",
    "Wavelets are short waveforms which are usually the impulse responses of\n",
    "filters.  Wavelet transforms employ banks of bandpass filters, whose impulse\n",
    "responses are scaled versions of each other, in\n",
    "order to get pass-bands in different parts of the frequency spectrum.  If the\n",
    "impulse response of a filter is scaled in time by a factor $a$, then the\n",
    "filter frequency response is scaled by the factor $1/a$.  Typically $a = 2$\n",
    "from one filter to the next, and each bandpass filter is designed to pass a\n",
    "2:1 range of frequencies (one octave). We can split an image up using wavelets by a process known as a _binary wavelet tree_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 The binary wavelet tree\n",
    "\n",
    "\n",
    "We start in 1-D with the\n",
    "simplest possible pair of filters, operating on just two input samples, $x_n$\n",
    "and $x_{n-1}$.  The two filter outputs, $u_n$ and $v_n$ at time $n$ are\n",
    "given by:\n",
    "$$\n",
    " u_n = \\tfrac{1}{2} (x_n + x_{n-1}) \\quad \\text{and} \\quad\n",
    " v_n = \\tfrac{1}{2} (x_n - x_{n-1})\n",
    "$$\n",
    "\n",
    "The first filter averages adjacent samples, and so rejects the higher\n",
    "frequency components of $x$, while the second filter differences these\n",
    "samples, and so rejects the lower frequency components.  These filters are\n",
    "known as the _analysis_ filter pair, $H_1(z) = \\tfrac{1}{2} (1 + z^{-1})$\n",
    "and $H_2(z) = \\tfrac{1}{2} (1 - z^{-1})$.  It is clear that we can recover the\n",
    "two input samples from the filter outputs using:\n",
    "$$\n",
    " x_n = u_n + v_n \\quad \\text{and} \\quad x_{n-1} = u_n - v_n\n",
    "$$\n",
    "\n",
    "Next it is important to note that we need only retain the samples of $u_n$\n",
    "and $v_n$ at even values of $n$ in order to be able to recover all the\n",
    "original samples of $x$.  Hence $u$ and $v$ may be decimated 2:1 and still\n",
    "allow perfect reconstruction of $x$.  If $x$ is a finite length vector (e.g. a\n",
    "row of image pixels), then $u$ and $v$ are each half as long as $x$, so the\n",
    "total number of samples is preserved by the transformation.\n",
    "\n",
    "A wavelet binary tree may be constructed using these filters, by using an\n",
    "identical pair, $H_1$ and $H_2$, to filter the decimated lowpass signal\n",
    "$u_{2n}$, to give a pair of outputs, $uu_{2n}$ and $uv_{2n}$, representing\n",
    "the lower and upper halves of the first low band.  These may again be\n",
    "decimated 2:1 and still permit perfect reconstruction of $u$.  This process\n",
    "may be continued as often as desired: each time splitting the lowest band in\n",
    "two, and decimating the sample rate of the filter outputs by 2:1.  At each\n",
    "stage the bandwidth of the two lowest filters is halved, and their impulse\n",
    "responses are doubled in length.  The total number of output samples remains\n",
    "constant, however many stages are used.\n",
    "\n",
    "For example, if $f_s$ is the input sample rate, a 3-stage binary tree will\n",
    "split the input signal bandwidth of 0 to $f_s/2$ into the following four\n",
    "bands:\n",
    "$$\n",
    "0 \\rightarrow f_s/16; \\ \\ f_s/16 \\rightarrow f_s/8; \\ \\ f_s/8 \\rightarrow\n",
    "f_s/4;  \\ \\ f_s/4 \\rightarrow f_s/2.\n",
    "$$\n",
    "\n",
    "The very simple filters, given above, do not generate a filter tree with\n",
    "good characteristics, since the wavelets turn out to be just a pair of\n",
    "square pulses.  These generate _blocking_ artefacts when used for image\n",
    "compression (in fact they are equivalent to the 2 point ($N=2$)\n",
    "DCT). A better set of filters are the LeGall 5 and 3 tap pair,\n",
    "given by:\n",
    "$$\n",
    " u_n = \\tfrac{1}{8} (-x_{n+2} + 2 x_{n+1} + 6 x_n + 2 x_{n-1} - x_{n-2})\n",
    "  \\quad \\text{ and }  \\quad\n",
    " v_{n+1} = \\tfrac{1}{4} (-x_{n+2} + 2 x_{n+1} - x_n)\n",
    "$$\n",
    "\n",
    "If $u$ and $v$ are decimated by 2 by choosing even $n$ only, the lowband outputs\n",
    "$u_n$ are centred on the even samples, and the highband outputs $v_{n+1}$ are\n",
    "centred on the odd samples.  This is very important to allow perfect\n",
    "reconstruction of $x$ from $u$ and $v$.\n",
    "\n",
    "The equations for reconstruction may be obtained by solving the above to get:\n",
    "\n",
    "\\begin{align}\n",
    " x_n &= \\tfrac{1}{2} (-v_{n+1} + 2 u_n - v_{n-1}) \\quad \\text{and}  \\\\\n",
    " x_{n+1} &= \\tfrac{1}{2} (x_{n+2} + 4 v_{n+1} + x_n) =\n",
    " \\tfrac{1}{4} (-v_{n+3} + 2 u_{n+2} + 6 v_{n+1} + 2 u_n - v_{n-1})\n",
    "\\end{align}\n",
    "\n",
    "In general, most analysis filters will not yield such simple reconstruction\n",
    "solutions, and the design of suitable filters is a non-trivial topic that we\n",
    "shall not cover here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.2 Applying the DWT to images\n",
    "\n",
    "\n",
    "As with the DCT, the 2-D DWT may be obtained by applying a 1-D transform to\n",
    "first the rows and then the columns of an image.\n",
    "\n",
    "Start by loading the Lighthouse image and defining the two LeGall\n",
    "filters given above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = load_mat_img(img='lighthouse.mat', img_info='X', cmap_info={'map', 'map2'})\n",
    "X = X - 128.0\n",
    "h1 = np.array([-1, 2, 6, 2, -1])/8\n",
    "h2 = np.array([-1, 2, -1])/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the function `rowdec` from the pyramid work, to\n",
    "produce a decimated and lowpass filtered version of the rows of\n",
    "`X` (remembering to subtract 128 as before) using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.laplacian_pyramid import rowdec\n",
    "U = rowdec(X, h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the high-pass image `V`, it is important to align the decimated\n",
    "samples with the odd columns of `X` (assuming the first column is $n = 0$)\n",
    "whereas `U` is aligned with the even columns.  To do this we use a\n",
    "slightly modified version of `rowdec`, called `rowdec2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.laplacian_pyramid import rowdec2\n",
    "V = rowdec2(X, h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Display `U` and `V` to see the outputs of the first filter pair\n",
    "and comment on their relative energies (or standard deviations). Note that `U` and `V` are half the width of `X`, but that `U` is otherwise similar to `X`.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "print(f'Energy in U: {np.sum(U**2)}, in V: {np.sum(V**2)} ')\n",
    "\n",
    "plot_image(U, ax=ax[0])\n",
    "plot_image(V, ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter the columns of `U` and `V` using `rowdec\n",
    "/ rowdec2` with the transpose operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UU = rowdec(U.T, h1).T\n",
    "UV = rowdec2(U.T, h2).T\n",
    "VU = rowdec(V.T, h1).T\n",
    "VV = rowdec2(V.T, h2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "Display `np.block([[UU, VU], [UV, VV]])`, and comment\n",
    "on what sort of edges or features are selected by each filter. You may need to multiply the high-pass images by a factor $k > 1$ to display them clearly. Why is this?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2 # Scale factor to make highpass images visible\n",
    "# probably because of how little energy they contain\n",
    "\n",
    "R = np.block([[UU, k*VU], [k*UV, k*VV]])\n",
    "\n",
    "plot_image(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must now check that it is possible to recover the image from\n",
    "these sub-images, using reconstruction filters, `g1` and `g2`, and the functions, `rowint` and `rowint` (which\n",
    "is modified in a similar way to `rowdec2` to allow correct\n",
    "alignment of the high-pass samples). To reconstruct `Ur` and\n",
    "`Vr` from `UU`, `UV`, `VU` and `VV` use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.laplacian_pyramid import rowint, rowint2\n",
    "\n",
    "g1 = np.array([1, 2, 1])/2\n",
    "g2 = np.array([-1, -2, 6, -2, -1])/4\n",
    "Ur = rowint(UU.T, g1).T + rowint2(UV.T, g2).T\n",
    "Vr = rowint(VU.T, g1).T + rowint2(VV.T, g2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the gain of 2 in the reconstruction filters, `g1` and\n",
    "`g2` (to compensate for losing half the samples in the\n",
    "decimation / interpolation processes).   These filters are also\n",
    "not quite the same as those that might be inferred from the\n",
    "equations for $x_n$ and $x_{n+1}$ on the previous page.  This is\n",
    "because `g1` defines how {\\it only} the $u$ samples contribute\n",
    "both to the even and odd samples of $x$, while `g2` defines\n",
    "how the $v$ samples contribute.\n",
    "\n",
    "Check that `Ur` and `Vr` are the same as `U` and\n",
    "`V`, and then reconstruct `Xr` from these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.testing.assert_equal(Ur, U))\n",
    "print(np.testing.assert_equal(Vr, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr = rowint(Ur,g1) + rowint2(Vr,g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that `Xr` is the same as `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.testing.assert_equal(X, Xr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above operations are a bit tedious to repeat if we want to\n",
    "apply the DWT recursively to obtain several levels of filtering,\n",
    "so we have written a pair of functions, `dwt` and `idwt`, to perform the 2-D analysis and reconstruction\n",
    "operations. Examine these to see that they perform the same\n",
    "operations as above, except that the transformed sub-images are\n",
    "stored as parts of a single matrix, the same size as `X`,\n",
    "rather than as separate matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.dwt import dwt\n",
    "IPython.display.Code(inspect.getsource(dwt), language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.dwt import idwt\n",
    "IPython.display.Code(inspect.getsource(idwt), language=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check their operation as below::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dwt(X)\n",
    "Xr = idwt(Y)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "plot_image(Y, ax=axs[0])\n",
    "axs[0].set(title=\"Y\")\n",
    "plot_image(Xr, ax=axs[1])\n",
    "axs[1].set(title=\"Xr\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Y` should be the same as the composite `[UU VU; UV VV]` image that\n",
    "you displayed earlier, and `Xr` should be the same as `X`.\n",
    "\n",
    "Now implement a multilevel DWT by first applying `dwt` to\n",
    "`X` using:\n",
    "\n",
    "```python\n",
    "m=256\n",
    "Y=dwt(X)\n",
    "plot_image(Y, ax=some_axis)\n",
    "```\n",
    "\n",
    "and then iteratively apply `dwt` to the top left sub-image\n",
    "of `Y` by repeating:\n",
    "```python\n",
    "m = m//2\n",
    "Y[:m,:m] = dwt(Y[:m,:m])\n",
    "plot_image(Y, ax=some_axis)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(15, 6))\n",
    "\n",
    "Y = X.copy()\n",
    "\n",
    "L = 5\n",
    "\n",
    "for i in range(L):\n",
    "    m = 256//(2**i)\n",
    "    Y[:m,:m] = dwt(Y[:m,:m])\n",
    "    plot_image(Y, ax=ax[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the image split using a binary wavelet tree (stricly a\n",
    "quaternary tree in 2-D).  Write\n",
    "similar iterative code to that given above, which can reconstruct\n",
    "the image from the final set of `Y` sub-images after a 4-level\n",
    "wavelet transform. Check that your reconstructed image is the\n",
    "same as `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr = Y.copy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(15, 6))\n",
    "\n",
    "for i in range(L):\n",
    "    m = 256//(2**(L - i - 1))\n",
    "    Yr[:m,:m] = idwt(Yr[:m,:m])\n",
    "    plot_image(Yr, ax=ax[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Quantisation and coding efficiency\n",
    "\n",
    "First rewrite the sequences of operations required to perform\n",
    "$n$ levels of DWT and inverse DWT as two separate M-files, `nlevdwt` and `nlevidwt`. `nlevdwt` should transform\n",
    "`X` into `Y`, and `nlevidwt` should inverse\n",
    "transform a quantised set of sub-images `Yq` into the\n",
    "reconstructed image `Z`.  Check your functions by ensuring\n",
    "that `Z` is the same as `X` if `Yq = Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlevdwt(X, n):\n",
    "    \n",
    "    Y = X.copy()\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        m = 256//(2**(i))\n",
    "        Y[:m,:m] = dwt(Y[:m,:m])\n",
    "\n",
    "    return Y\n",
    "\n",
    "def nlevidwt(Y, n):\n",
    "\n",
    "    Z = Y.copy()\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        m = 256//(2**(n - i - 1))\n",
    "        Z[:m,:m] = idwt(Z[:m,:m])\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check zero reconstruction error\n",
    "\n",
    "N = 4\n",
    "\n",
    "Z = nlevidwt(nlevdwt(X, N), N)\n",
    "\n",
    "print(np.max(np.abs(X - Z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now design a function, `quantdwt`, which will quantise the\n",
    "sub-images of `Y` to give `Yq` and calculate their\n",
    "entropy.  The sub-images at each level `i` of the DWT should\n",
    "be quantised according to a $3 \\times (n+1)$ matrix `dwtstep[k,i]` of\n",
    "step-sizes, where $\\mathtt{k}=\\left\\{0,1,2\\right\\}$ corresponds to each of the three high-pass images at level `i` (top right, bottom left, and bottom right, respectively), and the final low-pass image is quantised with `dwtstep[0,n]`. This matrix will be populated either with the same number in all elements (for equal-step-size quantisation) or a range of different numbers (for equal-MSE quantisation). The entropies for each sub-image should be stored in a similar $3 \\times (n+1)$ matrix `dwtent[k,i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size func\n",
    "\n",
    "def img_size(img):\n",
    "    return bpp(img) * img.shape[0] * img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.laplacian_pyramid import quantise, bpp\n",
    "\n",
    "# Quantise DWT image\n",
    "\n",
    "def quantdwt(Y: np.ndarray, dwtstep: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        Y: the output of `dwt(X, n)`\n",
    "        dwtstep: an array of shape `(3, n+1)`\n",
    "    Returns:\n",
    "        Yq: the quantized version of `Y`\n",
    "        dwtent: an array of shape `(3, n+1)` containing the entropies\n",
    "    \"\"\"\n",
    "    \n",
    "    n = dwtstep.shape[1] - 1 # number of times binary DWT is applied\n",
    "    Yq = np.zeros_like(Y)\n",
    "    dwtent = 0\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        m = 256//(2**i) # 256, 128, 64 ... \n",
    "        h = m//2 # Midpoint: 128, 64, 32 ...\n",
    "\n",
    "        # Quantising\n",
    "        Yq[:h, h:m] = quantise(Y[:h, h:m], dwtstep[0][i]) # Top right \n",
    "        Yq[h:m, :h] = quantise(Y[h:m, :h], dwtstep[1][i]) # Bottom left\n",
    "        Yq[h:m, h:m] = quantise(Y[h:m, h:m], dwtstep[2][i]) # Bottom right\n",
    "\n",
    "        # Find entropy of each from above\n",
    "        dwtent += img_size(Yq[:h, h:m]) + img_size(Yq[h:m, :h]) + img_size(Yq[h:m, h:m])\n",
    "\n",
    "\n",
    "    # Final low pass image\n",
    "    m = 256//(2**n)\n",
    "    Yq[:m, :m] = quantise(Y[:m, :m], dwtstep[0, n])\n",
    "    dwtent += img_size(Yq[:m, :m])\n",
    "    \n",
    "    return Yq, dwtent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these functions, for a given number of levels $n$ (typically\n",
    "between 3 and 5), you should generate `Y`, quantise it to\n",
    "give `Yq` and reconstruct `Z` from `Yq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "\n",
    "dwtstep = np.ones((3, N+1)) * 17\n",
    "\n",
    "Y = nlevdwt(X, N)\n",
    "Yq, ent = quantdwt(Y, dwtstep)\n",
    "Z = nlevidwt(Yq, N)\n",
    "\n",
    "print(f'Compression Ratio = {img_size(quantise(X, 17))/ent}')\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "plot_image(X, ax=ax[0])\n",
    "plot_image(Z, ax=ax[1])\n",
    "\n",
    "# This produces high compression high error with 17 as base step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our experiments thus far have been performed on only one image. At this stage it is worth starting to experiment with the additional `Bridge` image, as well as Lighthouse. Bridge contains a lot more fine detail and may not lead to the same conclusions regarding performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb, _ = load_mat_img(img='bridge.mat', img_info='X', cmap_info={'map'})\n",
    "Xb = Xb - 128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_image(Xb, ax=ax)\n",
    "ax.set(title=\"bridge.mat\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Investigate the performance of\n",
    "both an equal-step-size and an equal-MSE scheme (follow a similar procedure as you used for the Laplacian Pyramid to find the appropriate step-size ratios). Hence determine how many levels of DWT are reasonably optimal for the Lighthouse and Bridge images. Also evaluate the subjective quality of your reconstructed images, and comment on how this depends on $n$ and on the way that step-sizes are assigned\n",
    "to the different levels. Once again, for each image choose quantisation steps such that you match the rms error to that for direct quantisation with a step-size of 17.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energies between layers\n",
    "\n",
    "n = 7\n",
    "\n",
    "B = np.zeros_like(X)\n",
    "E = []\n",
    "\n",
    "Y = nlevdwt(B, n)\n",
    "\n",
    "for n in range(n):\n",
    "\n",
    "    Yp = Y.copy()\n",
    "\n",
    "    m = 256//(2**(i+2))\n",
    "    Yp[m, m] = 100\n",
    "    Z = nlevidwt(Yp, n)\n",
    "\n",
    "    E.append(np.sum(Z**2))\n",
    "\n",
    "\n",
    "for i in range(len(E)-1):\n",
    "\n",
    "    print(f'Energy ratio, layer {i+1} / layer {i}: \\t{E[i+1]/E[i]:.4}')\n",
    "\n",
    "# Tends towards 4 again? correct approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "# Modified laplacian pyramid optimisation function for DWT\n",
    "\n",
    "BASE_STEP = 17\n",
    "\n",
    "def optimum_step_size(n, ratio=1):\n",
    "\n",
    "    Xq = quantise(X, BASE_STEP)\n",
    "    directq_error = np.std(X - Xq)\n",
    "\n",
    "    def error_difference(steps):\n",
    "\n",
    "        Y = nlevdwt(X, n) # Decompose\n",
    "\n",
    "        # Set quantisation levels according to ratio and initial step\n",
    "        dwtstep = np.array([np.ones((1, 3))[0]*steps*(ratio**i) for i in range(n + 1)]).T\n",
    "        \n",
    "        Yq, ent = quantdwt(Y, dwtstep) # Quantise\n",
    "        Z = nlevidwt(Yq, n) # Decode\n",
    "\n",
    "        # Return difference in errors\n",
    "        zq_error = np.std(X - Z)\n",
    "        return (directq_error - zq_error) ** 2\n",
    "\n",
    "    res = optimize.minimize_scalar(error_difference, bounds=(1, 256) )\n",
    "    return res.x\n",
    "\n",
    "optimum_step_size(4, ratio=1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying DWT layer depth maintaining reference error with const. and equal MSE schemes\n",
    "\n",
    "Xq = quantise(X, BASE_STEP)\n",
    "entr = img_size(Xq)\n",
    "\n",
    "def optimise_depth(X):\n",
    "\n",
    "    fig, axs = plt.subplots(2, 6, sharex=True, sharey=True, figsize=(15, 6))\n",
    "\n",
    "    for i, n in enumerate(range(1, 7)):\n",
    "\n",
    "        Y = nlevdwt(X, n)\n",
    "\n",
    "        for j, r in enumerate([1, 1/2]):\n",
    "\n",
    "            steps = optimum_step_size(n, ratio=r)\n",
    "\n",
    "            dwtstep = np.array([np.ones((1, 3))[0]*steps*(r**i) for i in range(n + 1)]).T\n",
    "\n",
    "            Yq, ent = quantdwt(Y, dwtstep)\n",
    "\n",
    "            Z = nlevidwt(Yq, n)\n",
    "\n",
    "            print(f'{\"Constant\" if j == 0 else \"Eq. MSE\"} {n} layers\\t cr = {entr/ent:.4}\\t init. step = {steps:.4}\\t error = {np.std(Z - X):.4}')\n",
    "\n",
    "            plot_image(Z, ax=axs[j][i])\n",
    "    \n",
    "\n",
    "optimise_depth(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for bridge image\n",
    "\n",
    "optimise_depth(Xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Second Interim Report\n",
    "\n",
    "This report should include the new results from the DCT, LBT and DWT energy\n",
    "compaction methods in a format that will allow them to be compared with each other and contrasted to the\n",
    "Laplacian pyramid work in your first report.  Again try to answer questions\n",
    "raised in the text, and also include discussion of any topics that have led to\n",
    "unexpected results or have proved particularly interesting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf2",
   "language": "python",
   "name": "sf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
