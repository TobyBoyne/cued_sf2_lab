{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure id=\"figure-3\">\n",
    "<div style=\"background-color: white\">\n",
    "\n",
    "![](figures/dct.svg)</div>\n",
    "    \n",
    "<figcaption style=\"text-align: center\">Figure 3: A DCT can be treated as an N channel filter bank where the coefficients of the\n",
    "filters are the basis functions.</figcaption></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 The Discrete Cosine Transform (DCT)\n",
    "\n",
    "\n",
    "The DCT is a method of performing energy compaction that is rather different\n",
    "from the pyramid method.  It operates on non-overlapping blocks of pixels\n",
    "(typically $8 \\times 8$ pixels in size) by a reversible linear transform\n",
    "process, such that each block of pixels is replaced by a block of the same\n",
    "number of transform coefficients.  If all the transform coefficients for a\n",
    "given block are transmitted unaltered to the decoder, then the original block\n",
    "of pixels can be exactly recovered by the inverse transform process.\n",
    "\n",
    "In practise the transform coefficients are quantised before transmission, and\n",
    "if energy compaction has occurred, then fewer bits will be needed to send the\n",
    "coefficients than the original pixels.  A key advantage of transform-based\n",
    "methods is that there is no expansion of the number of samples (the\n",
    "transformed block is the same size as the original block of pixels), whereas\n",
    "the previous pyramid method expands the data by\n",
    "$1 + \\frac{1}{4} + \\frac{1}{16} + \\ldots \\approx 1.33$ times, which is not very desirable for data\n",
    "compression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Definition of the DCT\n",
    "\n",
    "\n",
    "The one-dimensional form of the DCT is closely related to the Discrete Fourier\n",
    "Transform (DFT).  The 1-D $N$-point DCT is defined as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "y(k) = \\sum_{n=0}^{N-1} C_{kn}\\ x(n) \\quad \\text{for} \\quad 0 \\le k \\le N-1 \\\\\n",
    "  \\text{where }\\quad C_{0n} = \\sqrt{\\frac{1}{N}}  \\\\\n",
    "    \\text{and } \\quad C_{kn} = \\sqrt{\\frac{2}{N}}\\ \\cos\n",
    "\\frac{k(n+\\frac{1}{2})\\pi}{N} \\quad \\text{for} \\quad 1 \\le k \\le N-1\n",
    "$$\n",
    "\n",
    "The equivalent inverse DCT is:\n",
    "$$\n",
    "x(n) = \\sum_{k=0}^{N-1} C_{kn}\\ y(k) \\quad \\text{for} \\quad 0 \\le n \\le N-1 \\\\\n",
    " \\text{where $C_{kn}$ is defined as above.}\\\\\n",
    "$$\n",
    "\n",
    "(This is actually the Type-II DCT, and the inverse is the Type-III DCT - other types have slightly different relative phases})\n",
    "\n",
    "We see that the forward transform is equivalent to multiplication of the\n",
    "$N$-point column vector $[x(0) \\ldots x(N-1)]'$ by an $N \\times N$ matrix,\n",
    "containing $C_{kn}$ at each location $(k,n)$, to produce the $N$-point column\n",
    "vector $[y(0) \\ldots y(N-1)]'$.  Similarly the inverse transform is equivalent\n",
    "to multiplication of the $y$ vector by the transpose of the $C$ matrix to give\n",
    "the $x$ vector.  In python3 + numpy notation these become:\n",
    "\n",
    "`y = C @ x` and `x = C.T @ y`\n",
    "\n",
    "Note that C is an orthonormal matrix since its inverse is just its\n",
    "transpose (its rows are othogonal to each other and have unit energy).\n",
    "\n",
    "The two-dimensional version of the DCT (as used for image compression) is a\n",
    "simple extension of the above 1-D DCT.  For an $N \\times N$ block of pixels,\n",
    "the $N$-point 1-D DCT is first applied to each column of the block to give $N$\n",
    "columns of coefficients.  Then the same 1-D DCT is applied to the rows of\n",
    "these coefficients to give the 2-D transform coefficients.\n",
    "\n",
    "In python3 + numpy notation, if the input block of pixels is matrix X, the output\n",
    "block of 2-D transformed coefficients Y is given by:\n",
    "\n",
    "`Y = (C @ (C @ X).T).T` or more simply `Y = C @ X @ C.T`\n",
    "\n",
    "where C is the 1-D transform matrix as above.  Note that in the 2-D\n",
    "transform, it does not matter whether the rows or the columns are transformed\n",
    "first (because the transform is linear and separable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Applying the DCT to images\n",
    "\n",
    "Conceptually the 2-D DCT is applied to all non-overlapping $N \\times N$ blocks\n",
    "of pixels in an image (we assume that the image dimensions are exact multiples\n",
    "of $N$).  However it is simplest and most efficient to perform 1-D\n",
    "$N$-point DCTs on all the columns of the image first, and then repeat the\n",
    "operation on the transpose of the result to transform the rows.\n",
    "\n",
    "**First generate an 8-point 1-D Type-II DCT matrix C8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.dct import dct_ii\n",
    "\n",
    "C8 = dct_ii(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the function `dct_ii` and list `C8` to check\n",
    "that it agrees with the definitions for $C_{kn}$ given above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import IPython.display\n",
    "IPython.display.Code(inspect.getsource(dct_ii), language=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the rows of `C8` using `plot(C8.T)`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(C8.T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When we calculate the 1-D transform of an 8-point block of data, each\n",
    "transform coefficient represents the component of the data that is\n",
    "correlated with the corresponding row of `C8`.  Hence the\n",
    "first coefficient represents the dc component, the second one\n",
    "represents the approximate average slope, and so on. The later\n",
    "coefficients represent progressively higher frequency components\n",
    "in the data.\n",
    "\n",
    "The function `colxfm(X, C8)` will perform a 1-D transform on\n",
    "the columns of image `X` using `C8`. We can\n",
    "therefore perform a 2-D transform on `X` by using `colxfm` twice, once with transpose operators, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.familiarisation import load_mat_img\n",
    "from cued_sf2_lab.dct import colxfm\n",
    "\n",
    "X_pre_zero_mean, cmaps_dict = load_mat_img(img='lighthouse.mat', img_info='X', cmap_info={'map', 'map2'})\n",
    "X = X_pre_zero_mean - 128.0\n",
    "\n",
    "Y = colxfm(colxfm(X, C8).T, C8).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `Y`, each $8 \\times 8$ block of pixels has been replaced by an\n",
    "equivalent block of transform coefficients.  The coefficient in the top left\n",
    "corner of each block represents the dc value of the block of pixels;\n",
    "coefficients along the top row represent increasing horizontal frequency\n",
    "components, and along the left column represent increasing vertical frequency\n",
    "components.  Other coefficients represent various combinations of horizontal\n",
    "and vertical frequencies, in proportion to their horizontal and vertical\n",
    "distances from the top left corner.\n",
    "\n",
    "If we try to display `Y` directly as an image, it is rather\n",
    "confusing because the different frequency components of each block\n",
    "are all present adjacent to each other.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.familiarisation import plot_image\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_image(Y, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much more meaningful\n",
    "image is created if we group all the coefficients of a given type\n",
    "together into a small sub-image, and display the result as an $8\n",
    "\\times 8$ block of sub-images, one for each coefficient type.  The\n",
    "function `regroup(Y, N)` achieves this regrouping, where $N$ is\n",
    "the size of the original transform blocks. You need to ensure that X has zero mean (by subtracting 128) before you start transforming it, otherwise the dc coefficient will be purely positive, whereas the\n",
    "others are symmetrically distributed about zero. Also, an $N\n",
    "\\times N$ 2-D DCT introduces a gain factor of $N$ in order to\n",
    "preserve constant total energy between the pixel and transform\n",
    "domains: we need to divide by $N$ *when displaying* to get back to the expected range.\n",
    "\n",
    "Hence we can display `Y` meaningfully using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.dct import regroup\n",
    "\n",
    "N = 8\n",
    "fig, ax = plt.subplots()\n",
    "plot_image(regroup(Y, N)/N, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this image, you should see a small replica of the original in the top left\n",
    "corner (the dc coefficients), and other sub-images showing various edges from\n",
    "the original, representing progressively higher frequencies as you move\n",
    "towards the lower right corner.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "What do you observe about the energies of the sub-images as frequencies\n",
    "increase?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of energies of sub-images\n",
    "fig, ax = plt.subplots()\n",
    "energies = np.zeros((N, N))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        energies[i, j] = (Y[i::N, j::N] ** 2).sum()\n",
    "\n",
    "ax.imshow(energies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check that you can recover the original image from Y\n",
    "by carrying out the inverse transform using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = colxfm(colxfm(Y.T, C8.T).T, C8.T)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_image(Z, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measure the maximum absolute error between X and Z\n",
    "to confirm this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.max( np.abs(X - Z) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DCT analyses each $8 \\times 8$ block of image pixels into a linear\n",
    "combination of sixty-four $8 \\times 8$ basis functions.  The following will generate\n",
    "an image comprising these basis functions (the `np.nan`s separate the sub-images as matplotlib draws them as transparent, and the `reshape` function converts from a matrix to a row vector):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack some NaNs\n",
    "bases = np.concatenate([np.full((8, 1), np.nan), C8, np.full((8, 1), np.nan)], axis=1)\n",
    "# Reshape\n",
    "bases_flat = np.reshape(bases, (-1, 1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = plot_image(255*bases_flat@bases_flat.T, ax=ax)\n",
    "fig.colorbar(im);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Explain how this image relates to the DCT coefficients.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Quantisation and Coding Efficiency\n",
    "\n",
    "We are now going to look at the effects of quantising the DCT coefficients\n",
    "fairly coarsely and determine the entropies of the coefficient sub-images.\n",
    "At this stage we shall quantise all sub-images with the same step-size,\n",
    "since they all are the same size and have unit energy gain from the\n",
    "quantiser to the output image (due to the orthonormal transform matrices).\n",
    "\n",
    "First quantise the transformed image Y using a step size\n",
    "of 17 to give Yq.  Then regroup Yq to form\n",
    "sub-images of each coefficient type as before, to give Yr. These sub-images have different probability distributions and we can take advantage of this later in coding them efficiently. Hence we get a better estimate of the number of bits required to code Yq by looking at the entropies of each of the re-grouped sub-images separately.\n",
    "\n",
    "**Write a function `dctbpp(Yr, N)` to calculate the total number of bits from a re-grouped image Yr, by using `bpp(Ys)` on each sub-image Ys of Yr, then multiplying each result by the number of pixels in the sub-image, and summing to give the total number of bits.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.laplacian_pyramid import bpp\n",
    "\n",
    "def img_size(img):\n",
    "    return bpp(img) * img.shape[0] * img.shape[1]\n",
    "\n",
    "def dctbpp(Yr, N):\n",
    "    bits = 0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            Ys = Yr[N*i:N*(i+1), N*j:N*(j+1)]\n",
    "            bits += img_size(Ys)\n",
    "\n",
    "    return bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Visualise Yr and comment on the distributions in each of the sub-images. Use the function `dctbpp(Yr, N)` that you have written to calculate the total number of bits, and compare it with just using `bpp(Yr)`, explaining your results.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.laplacian_pyramid import quantise\n",
    "Yq = quantise(Y, 17)\n",
    "Yr = regroup(Yq, N) / N\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_image(Yr)\n",
    "\n",
    "print(f\"{dctbpp(Yr, N)=:.4f}\")\n",
    "print(f\"{img_size(Yr)=:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Now reconstruct the output image `Z` from `Yq` and measure the rms\n",
    "error (standard deviation) between `X` and `Z`.  Compare this with the\n",
    "error produced by quantising `X` with a step-size of 17 to give `Xq`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = colxfm(colxfm(Yq.T, C8.T).T, C8.T)\n",
    "Xq = quantise(X, 17)\n",
    "\n",
    "print(f\"{np.std(X - Z)=:.4f}\")\n",
    "print(f\"{np.std(X - Xq)=:.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_image(Z, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***As with the Laplacian Pyramid, we really need to contrast compression ratios and visual results on compressed images with the same rms error. Re-use your step optimisation code to calculate the (non-integer) step size required in this case for the same rms error as quantising X with a step-size of 17.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation\n",
    "BASE_STEP = 17\n",
    "from scipy import optimize\n",
    "def optimum_step_size(Y):\n",
    "    Xq = quantise(X, BASE_STEP)\n",
    "    directq_error = np.std(X - Xq)\n",
    "\n",
    "    def error_difference(steps):\n",
    "        # Quantise Y\n",
    "        Yq = quantise(Y, steps)\n",
    "\n",
    "        # Decode\n",
    "        Zq = colxfm(colxfm(Yq.T, C8.T).T, C8.T)\n",
    "\n",
    "        # Return difference in errors\n",
    "        zq_error = np.std(X - Zq)\n",
    "        return (directq_error - zq_error) ** 2\n",
    "\n",
    "    res = optimize.minimize_scalar(error_difference, bounds=(1, 256) )\n",
    "    return res.x\n",
    "\n",
    "optimum_step_size(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Calculate the compression ratio for this scheme compared to direct quantisation. Use `dctbpp` to calculate the number of bits needed. Contrast the visual appearance of the DCT-compressed image, the directly quantised image, and the original image.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = optimum_step_size(Y)\n",
    "Yq = quantise(Y, step_size)\n",
    "Xq = quantise(X, 17)\n",
    "Yr = regroup(Yq, N) / N\n",
    "Zq = colxfm(colxfm(Yq.T, C8.T).T, C8.T)\n",
    "\n",
    "print(f\"{dctbpp(Yr, N)=:.1f}\")\n",
    "compression_ratio = img_size(Xq) / dctbpp(Yr, N)\n",
    "print(f\"{compression_ratio=:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, figsize=(12, 5))\n",
    "plot_image(X, ax=axs[0])\n",
    "plot_image(Xq, ax=axs[1])\n",
    "plot_image(Z, ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 7.4 Alternative transform sizes\n",
    "\n",
    "So far, we have concentrated on $8 \\times 8$ DCTs using C8\n",
    "as the 1-D transform matrix.  **Now generate 4-point and 16-point\n",
    "transform matrices, C4 and C16 using `dct_ii`.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Repeat the main measurements from the previous section, so as to obtain\n",
    "estimates of the number of bits and compression ratios for $4 \\times 4$ and $16 \\times 16$ DCTs when the\n",
    "rms errors are equivalent to those in your previous tests.  Also assess the\n",
    "relative subjective quality of the reconstructed images.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This analysis is in fact slightly biased because with larger transform sizes the function `dctbpp(Yr, N)` will use a greater number of smaller sub-images on which to calculate probability distributions. It may be better to use the same N in this function even when the actual transform changes; however whether this is more predictive of actual coding performance depends on what scanning method is used in the coding scheme.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "What happens in the limit if you use `dctbpp(Yr, 256)` (i.e. the entropy is calculated independently for each pixel)? Why is this the case, and why isn't this a realistic result?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Can you draw any conclusions about the best choice of transform size for the\n",
    "Lighthouse image?  Try to postulate what features in other images might make your\n",
    "conclusions different, and suggest why.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "8118fdaf61d044f3184783ed75d5b537f4e58ee9090554a668d17829c9ba2150"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
